{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9d9d0127",
      "metadata": {
        "id": "9d9d0127"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/miguel/miniconda3/envs/nlp_proj/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qacA6xUk6HZ7",
      "metadata": {
        "id": "qacA6xUk6HZ7"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dc17ae86",
      "metadata": {
        "id": "dc17ae86"
      },
      "outputs": [],
      "source": [
        "embeddings = np.load('embeddings.npy', mmap_mode='r')   # shape: (N, D)\n",
        "assert embeddings.ndim == 2\n",
        "N, D = embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "L4TNP0BJzXOo",
      "metadata": {
        "id": "L4TNP0BJzXOo"
      },
      "outputs": [],
      "source": [
        "filenames = np.load('filenames.npy', mmap_mode='r')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4AHU95mup68D",
      "metadata": {
        "id": "4AHU95mup68D"
      },
      "source": [
        "Query Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "332k10ZlrD0Y",
      "metadata": {
        "id": "332k10ZlrD0Y"
      },
      "outputs": [],
      "source": [
        "image_path = 'IMG_0018.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9h0buvk-p6R5",
      "metadata": {
        "id": "9h0buvk-p6R5"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "\n",
        "img = Image.open(image_path).convert(\"RGB\")\n",
        "img_t = transform(img).unsqueeze(0)  # shape: [1, 3, 224, 224]\n",
        "\n",
        "with torch.no_grad():\n",
        "    feats = model(img_t)       # shape: [1, 2048, 1, 1]\n",
        "    feats = feats.squeeze()    # shape: [2048]\n",
        "\n",
        "embedding_query = feats.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QaVIrFSf6W_H",
      "metadata": {
        "id": "QaVIrFSf6W_H"
      },
      "source": [
        "Brute Force ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "BYFvoNW753NI",
      "metadata": {
        "id": "BYFvoNW753NI"
      },
      "outputs": [],
      "source": [
        "def ann_naive(emb: np.ndarray, query_vec: np.ndarray, k: int):\n",
        "    \"\"\"\n",
        "    Naive L2 k-NN search using explicit Python looping.\n",
        "    emb: (N, D) numpy array\n",
        "    query_vec: (D,) numpy array\n",
        "    Returns (indices, distances)\n",
        "    \"\"\"\n",
        "    N, D = emb.shape\n",
        "    k = min(k, N)\n",
        "    q = query_vec.astype(np.float32)\n",
        "\n",
        "    # --- compute squared L2 distance for each embedding ---\n",
        "    dists = []\n",
        "    for i in range(N):\n",
        "        diff = emb[i] - q\n",
        "        d2 = float(np.dot(diff, diff))  # same as np.sum(diff**2)\n",
        "        dists.append((i, d2))\n",
        "\n",
        "    # --- sort by distance (ascending) ---\n",
        "    dists.sort(key=lambda x: x[1])\n",
        "\n",
        "    # --- take top-k ---\n",
        "    topk = dists[:k]\n",
        "    idx = [i for i, _ in topk]\n",
        "    scores = [d for _, d in topk]\n",
        "\n",
        "    return np.array(idx, dtype=int), np.array(scores, dtype=float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "Rvr7rBVj4aXN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvr7rBVj4aXN",
        "outputId": "06ba9700-8a04-4df7-be83-f17cb0643fd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([20934, 21100,  4687, 14014, 18868,  8132, 11690,  8782, 13416,\n",
            "        5137]), array([70.06198883, 70.39277649, 70.6230011 , 72.50684357, 72.68650055,\n",
            "       72.91902161, 73.40797424, 73.51124573, 73.81577301, 74.15214539]))\n",
            "CPU times: user 911 ms, sys: 55.5 ms, total: 966 ms\n",
            "Wall time: 98.2 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(ann_naive(embeddings, embedding_query, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zd7uDMcVvoAM",
      "metadata": {
        "id": "Zd7uDMcVvoAM"
      },
      "source": [
        "Paths to Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "jO-pWh_ovqAM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO-pWh_ovqAM",
        "outputId": "d19c2738-f4d4-4e50-cd50-d7b794b8900a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 23396 image ID mappings.\n"
          ]
        }
      ],
      "source": [
        "path_to_ids = {}\n",
        "for i in [0,1,2,3,4,5,6,7,8,9,'a','b','c','d','e']:\n",
        "    with open(f\"map0{i}.csv\", \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\",\")\n",
        "            path_to_ids[parts[0]] = parts[3][3:]\n",
        "print(f\"Loaded {len(path_to_ids)} image ID mappings.\")\n",
        "\n",
        "path_to_meta = {}\n",
        "with open(\"metadata0.py\", \"r\") as f:\n",
        "    for line in f:\n",
        "        curr_line = line[1:-1]\n",
        "        curr_line = curr_line.strip().split(\",\")\n",
        "        image_id = curr_line[0]\n",
        "        metadata = \",\".join(curr_line[1:])[:-1]\n",
        "        # id_to_meta[image_id] = metadata\n",
        "        path_to_meta[path_to_ids[image_id]] = json.loads(metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4EvlUMkmzPzX",
      "metadata": {
        "id": "4EvlUMkmzPzX"
      },
      "source": [
        "Matching Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "xncdHXeczSKf",
      "metadata": {
        "id": "xncdHXeczSKf"
      },
      "outputs": [],
      "source": [
        "def metadata_matches(node_meta: dict, query_metadata: dict) -> bool:\n",
        "    if not query_metadata:\n",
        "        return True\n",
        "\n",
        "    for query_key in query_metadata.keys():\n",
        "        if query_key not in node_meta.keys():\n",
        "            continue\n",
        "\n",
        "        op, target = query_metadata[query_key]\n",
        "\n",
        "        if op == \"exact\":\n",
        "            if query_key == \"item_weight\" and node_meta[query_key][0][\"value\"] != target:\n",
        "                return False\n",
        "            elif query_key == \"model_year\" and node_meta[query_key][0][\"value\"] != target:\n",
        "                return False\n",
        "            elif query_key == \"color\" and node_meta[query_key][0][\"value\"] != target:\n",
        "                return False\n",
        "            elif query_key == \"country\" and node_meta[query_key] != target:\n",
        "                return False\n",
        "            elif query_key == \"brand\" and node_meta[query_key][0][\"value\"] != target:\n",
        "                return False\n",
        "\n",
        "        elif op == \"leq\":\n",
        "            if query_key == \"item_weight\" and node_meta[query_key][0][\"value\"] > target:\n",
        "                return False\n",
        "            elif query_key == \"model_year\" and node_meta[query_key][0][\"value\"] > target:\n",
        "                return False\n",
        "\n",
        "        elif op == \"geq\":\n",
        "            if query_key == \"item_weight\" and node_meta[query_key][0][\"value\"] < target:\n",
        "                return False\n",
        "            elif query_key == \"model_year\" and node_meta[query_key][0][\"value\"] < target:\n",
        "                return False\n",
        "\n",
        "    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Cj5ojBwZ207s",
      "metadata": {
        "id": "Cj5ojBwZ207s"
      },
      "source": [
        "Pre-Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "61y7ssDa6hr6",
      "metadata": {
        "id": "61y7ssDa6hr6"
      },
      "outputs": [],
      "source": [
        "def prefilter_search(query_vec: np.ndarray,\n",
        "                     query_meta: dict,\n",
        "                     embeddings: np.ndarray,\n",
        "                     filenames: np.ndarray,\n",
        "                     path_to_meta: dict,\n",
        "                     top_k: int = 10):\n",
        "    \"\"\"\n",
        "    1) Use metadata to restrict to a subset of indices.\n",
        "    2) Run k-NN ONLY within that subset.\n",
        "\n",
        "    Good when metadata is selective (subset is small).\n",
        "    \"\"\"\n",
        "    assert query_vec.shape == (embeddings.shape[1],)\n",
        "\n",
        "    # 1) Collect indices that match the metadata\n",
        "    candidate_indices = []\n",
        "    for i, fname in enumerate(filenames):\n",
        "        fname = str(fname)\n",
        "        node_meta = path_to_meta.get(fname, {})\n",
        "        if metadata_matches(node_meta, query_meta):\n",
        "            candidate_indices.append(i)\n",
        "\n",
        "    print(f\"[Pre-filter] Matched {len(candidate_indices)} of {len(filenames)} items.\")\n",
        "\n",
        "    if not candidate_indices:\n",
        "        return []\n",
        "\n",
        "    # 2) Run k-NN only on those candidates\n",
        "    sub_emb = embeddings[candidate_indices]\n",
        "    local_idx, scores = ann_naive(sub_emb, query_vec, k=top_k)\n",
        "\n",
        "    results = []\n",
        "    for rank, (li, score) in enumerate(zip(local_idx, scores)):\n",
        "        global_idx = candidate_indices[li]\n",
        "        fname      = str(filenames[global_idx])\n",
        "        results.append({\n",
        "            \"rank\":   rank,\n",
        "            \"index\":  int(global_idx),\n",
        "            \"file\":   fname,\n",
        "            \"score\":  float(score),\n",
        "            \"meta\":   path_to_meta.get(fname, {})\n",
        "        })\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J0xnMSCA3gda",
      "metadata": {
        "id": "J0xnMSCA3gda"
      },
      "source": [
        "Post-Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "t817Tvm63c6U",
      "metadata": {
        "id": "t817Tvm63c6U"
      },
      "outputs": [],
      "source": [
        "def postfilter_search(query_vec: np.ndarray,\n",
        "                      query_meta: dict,\n",
        "                      embeddings: np.ndarray,\n",
        "                      filenames: np.ndarray,\n",
        "                      path_to_meta: dict,\n",
        "                      top_k: int = 10,\n",
        "                      large_k: int = 200):\n",
        "    \"\"\"\n",
        "    1) Compute k-NN over the WHOLE collection (or ANN results).\n",
        "    2) Walk results in similarity order and keep only those that match metadata.\n",
        "\n",
        "    Good when you want strong semantic ranking and metadata is not super selective.\n",
        "    \"\"\"\n",
        "    assert query_vec.shape == (embeddings.shape[1],)\n",
        "\n",
        "    # Get a larger candidate set than final top_k so metadata filtering has room\n",
        "    k_all = min(large_k, embeddings.shape[0])\n",
        "    cand_idx, cand_scores = ann_naive(embeddings, query_vec, k=k_all)\n",
        "\n",
        "    results = []\n",
        "    for rank_all, (idx, score) in enumerate(zip(cand_idx, cand_scores)):\n",
        "        fname = str(filenames[idx])\n",
        "        node_meta = path_to_meta.get(fname, {})\n",
        "        if metadata_matches(node_meta, query_meta):\n",
        "            results.append({\n",
        "                \"rank\":   len(results),   # rank after metadata filtering\n",
        "                \"index\":  int(idx),\n",
        "                \"file\":   fname,\n",
        "                \"score\":  float(score),\n",
        "                \"meta\":   node_meta\n",
        "            })\n",
        "            if len(results) == top_k:\n",
        "                break\n",
        "\n",
        "    print(f\"[Post-filter] Returned {len(results)} results (from {k_all} ANN candidates).\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9XHknPqazmk7",
      "metadata": {
        "id": "9XHknPqazmk7"
      },
      "outputs": [],
      "source": [
        "query_meta = {\"country\": [\"exact\", \"US\"], \"item_weight\": [\"geq\", 0.3]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "SZTUGsWfz8Xr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZTUGsWfz8Xr",
        "outputId": "0ae318b7-17f2-432e-85c9-2f78e5e2cf8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== PREFILTER SEARCH ===\n",
            "[Pre-filter] Matched 5153 of 23396 items.\n",
            "4687 032f5f9c.jpg\n",
            "548 0001b659.jpg\n",
            "8328 05d37d4c.jpg\n",
            "CPU times: user 29.4 ms, sys: 7.68 ms, total: 37.1 ms\n",
            "Wall time: 36.4 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"=== PREFILTER SEARCH ===\")\n",
        "pre_results = prefilter_search(\n",
        "    query_vec=embedding_query,\n",
        "    query_meta=query_meta,\n",
        "    embeddings=embeddings,\n",
        "    filenames=filenames,\n",
        "    path_to_meta=path_to_meta,\n",
        "    top_k=3,\n",
        ")\n",
        "for r in pre_results:\n",
        "    print(r[\"index\"], r[\"file\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "-sLpc-BK0Mqr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sLpc-BK0Mqr",
        "outputId": "37dba44c-eb5b-4c08-a4c3-e57cb22d7ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== POSTFILTER SEARCH ===\n",
            "[Post-filter] Returned 3 results (from 200 ANN candidates).\n",
            "4687 032f5f9c.jpg\n",
            "548 0001b659.jpg\n",
            "8328 05d37d4c.jpg\n",
            "CPU times: user 58.8 ms, sys: 1.73 ms, total: 60.6 ms\n",
            "Wall time: 60.1 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"\\n=== POSTFILTER SEARCH ===\")\n",
        "post_results = postfilter_search(\n",
        "    query_vec=embedding_query,\n",
        "    query_meta=query_meta,\n",
        "    embeddings=embeddings,\n",
        "    filenames=filenames,\n",
        "    path_to_meta=path_to_meta,\n",
        "    top_k=3,\n",
        "    large_k=200,\n",
        ")\n",
        "for r in post_results:\n",
        "    print(r[\"index\"], r[\"file\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_proj",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
